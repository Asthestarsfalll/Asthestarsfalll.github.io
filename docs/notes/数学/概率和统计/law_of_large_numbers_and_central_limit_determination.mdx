---
title: 大数定律和中心极限定理
tags: [probability theory and mathematical statistics]
hide_table_of_contents: false
---

## 切比雪夫不等式

对于随机变量 $X$，其期望方差存在，对于任意的 $\epsilon>0$ ，总有

$$
P\{|X-E(X)|\geq\epsilon\}\leq \frac{D(X)}{\epsilon^2}
$$

或

$$
P\{|X-E(X)|\leq\epsilon\}\geq 1- \frac{D(X)}{\epsilon^2}
$$

:::info 切比雪夫不等式在干什么

其描述了事件大多会聚集在均值的附近。

:::

**马尔科夫不等式**

切比雪夫不等式是马尔科夫不等式的特殊情况，马尔科夫不等式的公式如下

$$
P(X\geq a)\leq \frac{E(X)}{a}
$$

切比雪夫不等式的可以这么写

$$
P(|X-\mu|>k\sigma)< \frac{1}{k^2}
$$

证明见 [此](https://www.zhihu.com/tardis/bd/ans/248693398?source_id=1001)

## 大数定律

:::tip 大数定律

当 **独立重复** 的随机事件 **发生的次数足够多** 时，随机事件发生的频率趋近于预期的概率。可以简单理解为样本数量越多，其平概率越接近于期望值。即可以使用频率代替概率，使用样本均值代替总体均值。

:::

**弱大数定律**

设随机变量序列 $X_{1},X_{2},\cdots,X_{n}\cdots$ ，$A$ 是一个常数，如果对任意 $\epsilon>0$，有

$$
\lim_{ n \to \infty } P\{|X_{n}-A|<\epsilon\}=1
$$

则称其 **依概率收敛于常数 A**.

:::tip 依概率收敛

落在区域外的概率很小，但不是 $0$.

:::

与其对应的是 **强大数定律**，而是 **几乎必然收敛**，即没有落在区域外的概率，即便有，这些落在区域外的点也可以忽略。

:::info

弱大数定律证明：随着 n 的增大，平均值接近真实期望值的可能性也在增大。

强大数定律证明：随着 n 的增大，平均值基本上就接近真实期望值了。

:::

### 伯努利大数定律

:::tip

从定义概率的角度，**揭示了概率与频率的关系**，当 $N$ 很大的时候，事件 $A$ 发生的概率等于 $A$ 发生的频率。

:::

对于随机变量 $X_{n}\sim B(n,p),n=1,2,3\cdots$，则对于任意的 $\epsilon>0$，有

$$
\lim_{ n \to \infty } P\left\{ \left| \frac{X_{n}}{n}-p \right|<\epsilon \right\}=1
$$

设 $f_{n}$ 为 $n$ 重伯努利事件中 $A$ 发生的次数， 即 $n$ 趋向于无穷大时，事件 $A$ 在 $n$ 重伯努利事件中发生的频率 $\frac{f_{n}}{n}$ 无限接近于事件 $A$ 在一次实验中发生的概率 $p$.

### 辛钦大数定律

:::tip

从理论上指出：用算术平均值来近似实际真值是合理的。

:::

对于 **独立同分布** 的随机变量，其有数学期望，则对任意 $\epsilon>0$

$$
\lim_{ n \to \infty } P\left\{ \left| \frac{1}{n}\sum_{i=1}^nX_{i}-\mu \right| <\epsilon\right\}=1
$$

当 $X_{i}$ 为服从 $0 -1$ 分布的随机变量时，辛钦大数定律就是伯努利大数定律，故**伯努利大数定律是辛钦伯努利大数定律的一个特例。**

### 切比雪夫大数定律

:::tip

**揭示了样本均值和真实期望的关系**。

:::

对于两两不相关的随机变量序列 （不要求同分布），存在常数 $C$，使得 $D(X_{i})<C$，则对于任意的 $\epsilon>0$，有

$$
\lim_{ n \to \infty } \left\{  \left|\frac{1}{n}\sum_{i=1}^nX_{i}- \frac{1}{n}\sum_{i=1}^nE(X_{i})\right|<\epsilon  \right\}=1
$$

### 对比

|   大数定律   | 分布     |  期望    |  方差    |  用途    |
|:-----|:-----|:-----|:-----|:-----|
| 伯努利     |  二项分布    |   相同   |  相同    |    估算概率  |
|  辛钦    |  独立同分布    |   相同   |   无要求   |   估算期望   |
|  切比雪夫    |  独立    |   存在   | 存在且有限     | 估算期望     |

## 中心极限定理

:::tip

中心极限定理指的是给定一个任意分布的总体。每次从这些总体中随机抽取 $n$ 个抽样（一般认为 $n>30$ 即可），一共抽 $m$ 次。分别求出这 $m$ 组抽样的均值。这些平均值的分布接近正态分布。

:::

:::caution 中心极限定理和大数定律是否矛盾

中心极限定理指的是当 $n$ 趋于无穷大，样本均值的极限抽样分布是正态分布，而大数定律指的是当 $n$ 趋于无穷大，样本均值应该更加总体均值。

这说的其实是一个事情，只是该正态分布的均值趋近于总体均值，方差趋近于 $0$，因此抽样所产生的正态分布图像往往是瘦长的，几乎所有概率都集中在均值附近。

:::

### 棣莫弗 - 拉普拉斯中心极限定理

对于随机变量 $X_{n}\sim B(n,p)(n=1,2,\cdots)$，则对于任意的实数 $x$，有

$$
\lim_{ n \to \infty } P\left\{ \left| \frac{\sum_{i=1}^nX_{i}-np}{\sqrt{ np(1-p) }} \right| \leq x\right\}=\Phi(x)
$$

其中 $\Phi(x)$ 是标准正态的分布函数。

:::info

上式中实际上是一个标准化的步骤，因此服从标准正态分布，也可以说 $\sum_{i=1}^nX_{n}\sim N(np,np(1-p))$，则 $\overline{X}\sim N\left( p, \frac{p(1-p)}{n} \right)$

注意：这里的 $n$ 足够大，因此方差是趋向于 $0$ 的，正好呼应上文中所说的中心极限定理与大数定律是否矛盾。

:::

### 列维 - 林德博格中心极限定理

随机变量序列 $X_{n}$ 独立同分布，且有方差和期望，则对于任意的实数 $x$，有

$$
\lim_{ n \to \infty } P\left\{  \frac{\sum_{i=1}^nX_{i}-n\mu}{\sqrt{ n }\sigma} \leq x \right\}=\lim_{ n \to \infty }P\left\{\frac{\sqrt{ n }}{\sigma}(\overline X-\mu)\leq x\right\} \Phi(x)
$$

:::info

同样的，$\sum_{i=1}^nX_{i}$ 近似服从 $N(n\mu,n\sigma^2)$，然而这里 $n\sigma^2$ 并没有趋向于 $0$，又该怎么解释？

:::
