{
  "main": {
    "id": "68a21184de113791",
    "type": "split",
    "children": [
      {
        "id": "edbcfc4f2208b705",
        "type": "tabs",
        "children": [
          {
            "id": "268b6d09ebf702fa",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":true},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":0,\"ch\":3},\"to\":{\"line\":0,\"ch\":0}}}"
                },
                {
                  "title": "pi0",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/EmbodiedIntelligence/pi0.md\",\"mode\":\"source\",\"source\":true},\"icon\":\"lucide-file\",\"title\":\"pi0\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":0,\"ch\":0},\"to\":{\"line\":0,\"ch\":0}}}"
                },
                {
                  "title": "flow_matching",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/Flow/flow_matching.md\",\"mode\":\"source\",\"source\":true},\"icon\":\"lucide-file\",\"title\":\"flow_matching\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":8,\"ch\":3},\"to\":{\"line\":8,\"ch\":3}},\"scroll\":0}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":0,\"ch\":0},\"to\":{\"line\":0,\"ch\":0}}}"
                },
                {
                  "title": "flow_matching",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/Flow/flow_matching.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"flow_matching\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":48,\"ch\":146},\"to\":{\"line\":48,\"ch\":146}},\"scroll\":0}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":0,\"ch\":0},\"to\":{\"line\":0,\"ch\":0}},\"scroll\":0}"
                },
                {
                  "title": "flow_matching",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/Flow/flow_matching.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"flow_matching\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":50,\"ch\":2},\"to\":{\"line\":50,\"ch\":2}},\"scroll\":49.552083333333336}"
                },
                {
                  "title": "pi0",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/EmbodiedIntelligence/pi0.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"pi0\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":3,\"ch\":0},\"to\":{\"line\":3,\"ch\":0}},\"scroll\":0.725}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":20,\"ch\":38},\"to\":{\"line\":20,\"ch\":38}},\"scroll\":14.514198331429899}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":195,\"ch\":59},\"to\":{\"line\":195,\"ch\":59}},\"scroll\":220.10119047619048}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/index.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":5,\"ch\":0},\"to\":{\"line\":5,\"ch\":0}},\"scroll\":0}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":101,\"ch\":0},\"to\":{\"line\":101,\"ch\":0}},\"scroll\":98.1535597952536}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/index.mdx\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":5,\"ch\":0},\"to\":{\"line\":5,\"ch\":0}}}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":9,\"ch\":0},\"to\":{\"line\":9,\"ch\":0}},\"scroll\":0}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":97,\"ch\":0},\"to\":{\"line\":97,\"ch\":0}},\"scroll\":88.25568181818181}"
                },
                {
                  "title": "flow_matching",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/Flow/flow_matching.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"flow_matching\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":9,\"ch\":0},\"to\":{\"line\":9,\"ch\":0}},\"scroll\":0}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":13,\"ch\":38},\"to\":{\"line\":13,\"ch\":38}},\"scroll\":13.121212121212121}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/index.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":5,\"ch\":0},\"to\":{\"line\":5,\"ch\":0}},\"scroll\":0}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":20,\"ch\":132},\"to\":{\"line\":20,\"ch\":132}},\"scroll\":25.61032196969697}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/index.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":5,\"ch\":0},\"to\":{\"line\":5,\"ch\":0}}}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":9,\"ch\":0},\"to\":{\"line\":9,\"ch\":0}},\"scroll\":0}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":9,\"ch\":0},\"to\":{\"line\":9,\"ch\":0}},\"scroll\":15.561079545454545}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":147,\"ch\":87},\"to\":{\"line\":147,\"ch\":0}},\"scroll\":138.0189393939394}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/index.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":5,\"ch\":0},\"to\":{\"line\":5,\"ch\":0}},\"scroll\":34.95669553630913}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":63,\"ch\":106},\"to\":{\"line\":63,\"ch\":106}},\"scroll\":63.09138257575758}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/index.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":26,\"ch\":25},\"to\":{\"line\":26,\"ch\":25}},\"scroll\":22.863636363636363}"
                },
                {
                  "title": "Proximal_Policy_Optimization",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"Proximal_Policy_Optimization\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":9,\"ch\":0},\"to\":{\"line\":9,\"ch\":0}}}"
                },
                {
                  "title": "index",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/index.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"index\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":5,\"ch\":0},\"to\":{\"line\":5,\"ch\":0}}}"
                },
                {
                  "title": "GRPO",
                  "icon": "lucide-file",
                  "state": "{\"type\":\"markdown\",\"state\":{\"file\":\"deeplearning/ReinforcementLearning/GRPO.md\",\"mode\":\"source\",\"source\":false},\"icon\":\"lucide-file\",\"title\":\"GRPO\"}",
                  "eState": "{\"cursor\":{\"from\":{\"line\":9,\"ch\":0},\"to\":{\"line\":9,\"ch\":0}}}"
                },
                {
                  "title": "Release Notes 1.8.10",
                  "icon": "lucide-book-up",
                  "state": "{\"type\":\"release-notes\",\"state\":{\"currentVersion\":\"1.8.10\"},\"icon\":\"lucide-book-up\",\"title\":\"Release Notes 1.8.10\"}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "markdown",
              "state": {
                "file": "deeplearning/Flow/flow_matching.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "flow_matching"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "ef5099b6bde5f82d",
    "type": "split",
    "children": [
      {
        "id": "5f1895091c29c3f3",
        "type": "tabs",
        "children": [
          {
            "id": "efb1e4a87529c3a5",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical",
                "autoReveal": false
              },
              "icon": "lucide-folder-closed",
              "title": "文件列表"
            }
          },
          {
            "id": "73bedc555d1dd18f",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "search",
              "state": {
                "query": "",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "搜索"
            }
          },
          {
            "id": "1a93dee25600b5d2",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "书签"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 318.5
  },
  "right": {
    "id": "2cb931200911f1fe",
    "type": "split",
    "children": [
      {
        "id": "b29f971e8d9e76ff",
        "type": "tabs",
        "children": [
          {
            "id": "8aa11a19fb8d6f33",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "backlink",
              "state": {
                "file": "meaningless/BPD/index.md",
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "index 的反向链接列表"
            }
          },
          {
            "id": "3fb6fac06a14f30c",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "outgoing-link",
              "state": {
                "file": "meaningless/BPD/index.md",
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "index 的出链列表"
            }
          },
          {
            "id": "023dbc10114ab08a",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "标签"
            }
          },
          {
            "id": "108985556a5fca36",
            "type": "leaf",
            "pane-relief:history-v1": {
              "pos": 0,
              "stack": [
                {
                  "state": "{}",
                  "eState": "{}"
                }
              ]
            },
            "state": {
              "type": "outline",
              "state": {
                "file": "meaningless/BPD/index.md"
              },
              "icon": "lucide-list",
              "title": "index 的大纲"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "canvas:新建白板": false,
      "switcher:打开快速切换": true,
      "graph:查看关系图谱": true,
      "daily-notes:打开/创建今天的日记": true,
      "templates:插入模板": true,
      "command-palette:打开命令面板": true,
      "markdown-importer:打开 Markdown 格式转换器": false,
      "darlal-switcher-plus:Open in Headings Mode": false,
      "darlal-switcher-plus:Open Symbols for the active editor": false
    }
  },
  "active": "268b6d09ebf702fa",
  "lastOpenFiles": [
    "deeplearning/ReinforcementLearning/GRPO.md",
    "deeplearning/EmbodiedIntelligence/pi0.md",
    "deeplearning/Flow/flow_matching.md",
    "deeplearning/ReinforcementLearning/Proximal_Policy_Optimization.md",
    "deeplearning/EmbodiedIntelligence",
    "deeplearning/ReinforcementLearning/images/grpo.png",
    "deeplearning/ReinforcementLearning/images/250521_16h38m31s_screenshot.png",
    "deeplearning/ReinforcementLearning/images/actor.png",
    "deeplearning/ReinforcementLearning/index.md",
    "deeplearning/index.mdx",
    "deeplearning/ReinforcementLearning/images/250521_16h13m59s_screenshot.png",
    "deeplearning/ReinforcementLearning/images",
    "未命名.canvas",
    "未命名 1.canvas",
    "deeplearning/Evaluation/GREEN.md",
    "deeplearning/Flow",
    "Dictionary/advanced_math.mdx",
    "'./images/20250416165128.png.md",
    "'./images",
    "'.",
    "deeplearning/Evaluation/images/20250416165128.png",
    "deeplearning/Multimodal/DALL-E.mdx",
    "deeplearning/Multimodal/clip.md",
    "deeplearning/Evaluation/images",
    "deeplearning/Evaluation/Boundary-IoU.mdx",
    "deeplearning/Evaluation/index.md",
    "Pasted image 20250415145201.png",
    "meaningless/其他的我/对喜欢的人有什么表现.md",
    "meaningless/其他的我/拉黑.md",
    "meaningless/其他的我/脆弱.md",
    "meaningless/其他的我/黑暗面.md",
    "Pasted image 20250415145207.png",
    "meaningless/其他的我/index.md",
    "meaningless/Onism/about.md",
    "meaningless/其他的我/最真实的悲伤.md",
    "meaningless/博客收录/Things-that-we-lose-finally.md",
    "meaningless/博客收录/奇怪的人类.md",
    "meaningless/博客收录/关于自残与自杀.md",
    "meaningless/古诗词/雨霖铃·寒蝉凄切.md",
    "meaningless/其他的我/子弹是故意打偏的.md",
    "meaningless/其他的我/虚无.md",
    "meaningless/其他的我/心理创伤.md",
    "meaningless/BPD/亲密关系.md",
    "meaningless/语录/love.md",
    "deeplearning/ComputerVision/Segmentation/images/240915_13h22m37s_screenshot.png",
    "deeplearning/ComputerVision/Segmentation/images/240915_12h42m11s_screenshot.png",
    "deeplearning/ComputerVision/Segmentation/images/240915_12h07m19s_screenshot.png",
    "G.canvas"
  ]
}